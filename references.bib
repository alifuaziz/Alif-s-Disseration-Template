
@misc{fsl_course_1_2020,
	title = {1. {Introduction} to {Brain} {Extraction} and {Registration} ({Reg} {E1})},
	url = {https://www.youtube.com/watch?v=3ExL6J4BIeo},
	abstract = {Introduction to Brain Extraction and Registration},
	urldate = {2024-04-24},
	author = {{FSL Course}},
	month = oct,
	year = {2020},
}

@misc{noauthor_buy_nodate,
	title = {Buy {These} {Books} - {Essential} {Library} for {Studying} {Western} {Esotericism} \& the {Occult} - {YouTube}},
	url = {https://www.youtube.com/},
	abstract = {Enjoy the videos and music you love, upload original content, and share it all with friends, family, and the world on YouTube.},
	language = {en},
	urldate = {2024-04-19},
}

@inproceedings{boser_training_1992,
	address = {New York, NY, USA},
	series = {{COLT} '92},
	title = {A training algorithm for optimal margin classifiers},
	isbn = {978-0-89791-497-0},
	url = {https://dl.acm.org/doi/10.1145/130385.130401},
	doi = {10.1145/130385.130401},
	abstract = {A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms.},
	urldate = {2024-04-08},
	booktitle = {Proceedings of the fifth annual workshop on {Computational} learning theory},
	publisher = {Association for Computing Machinery},
	author = {Boser, Bernhard E. and Guyon, Isabelle M. and Vapnik, Vladimir N.},
	month = jul,
	year = {1992},
	pages = {144--152},
}

@inproceedings{boser_training_1992-1,
	address = {New York, NY, USA},
	series = {{COLT} '92},
	title = {A training algorithm for optimal margin classifiers},
	isbn = {978-0-89791-497-0},
	url = {https://dl.acm.org/doi/10.1145/130385.130401},
	doi = {10.1145/130385.130401},
	abstract = {A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms.},
	urldate = {2024-04-08},
	booktitle = {Proceedings of the fifth annual workshop on {Computational} learning theory},
	publisher = {Association for Computing Machinery},
	author = {Boser, Bernhard E. and Guyon, Isabelle M. and Vapnik, Vladimir N.},
	month = jul,
	year = {1992},
	pages = {144--152},
}

@incollection{cristianini_support_2008,
	address = {Boston, MA},
	title = {Support {Vector} {Machines}},
	isbn = {978-0-387-30162-4},
	url = {https://doi.org/10.1007/978-0-387-30162-4_415},
	language = {en},
	urldate = {2024-04-08},
	booktitle = {Encyclopedia of {Algorithms}},
	publisher = {Springer US},
	author = {Cristianini, Nello and Ricci, Elisa},
	editor = {Kao, Ming-Yang},
	year = {2008},
	doi = {10.1007/978-0-387-30162-4_415},
	pages = {928--932},
}

@article{lee_neural_2015,
	title = {Neural {Computations} {Mediating} {One}-{Shot} {Learning} in the {Human} {Brain}},
	volume = {13},
	issn = {1545-7885},
	url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002137},
	doi = {10.1371/journal.pbio.1002137},
	abstract = {Incremental learning, in which new knowledge is acquired gradually through trial and error, can be distinguished from one-shot learning, in which the brain learns rapidly from only a single pairing of a stimulus and a consequence. Very little is known about how the brain transitions between these two fundamentally different forms of learning. Here we test a computational hypothesis that uncertainty about the causal relationship between a stimulus and an outcome induces rapid changes in the rate of learning, which in turn mediates the transition between incremental and one-shot learning. By using a novel behavioral task in combination with functional magnetic resonance imaging (fMRI) data from human volunteers, we found evidence implicating the ventrolateral prefrontal cortex and hippocampus in this process. The hippocampus was selectively “switched” on when one-shot learning was predicted to occur, while the ventrolateral prefrontal cortex was found to encode uncertainty about the causal association, exhibiting increased coupling with the hippocampus for high-learning rates, suggesting this region may act as a “switch,” turning on and off one-shot learning as required.},
	language = {en},
	number = {4},
	urldate = {2024-04-05},
	journal = {PLOS Biology},
	author = {Lee, Sang Wan and O’Doherty, John P. and Shimojo, Shinsuke},
	month = apr,
	year = {2015},
	note = {Publisher: Public Library of Science},
	keywords = {Behavior, Functional magnetic resonance imaging, Hippocampus, Learning, Memory, Prefrontal cortex, Sensory cues, Statistical data},
	pages = {e1002137},
}

@article{lee_brain-inspired_2022,
	title = {Brain-inspired {Predictive} {Coding} {Improves} the {Performance} of {Machine} {Challenging} {Tasks}},
	volume = {16},
	issn = {1662-5188},
	url = {https://www.frontiersin.org/articles/10.3389/fncom.2022.1062678},
	doi = {10.3389/fncom.2022.1062678},
	abstract = {Backpropagation has been regarded as the most favorable algorithm for training artificial neural networks. However, it has been criticized for its biological implausibility because its learning mechanism contradicts the human brain. Although backpropagation has achieved super-human performance in various machine learning applications, it often shows limited performance in specific tasks. We collectively referred to such tasks as machine-challenging tasks (MCTs) and aimed to investigate methods to enhance machine learning for MCTs. Specifically, we start with a natural question: Can a learning mechanism that mimics the human brain lead to the improvement of MCT performances? We hypothesized that a learning mechanism replicating the human brain is effective for tasks where machine intelligence is difficult. Multiple experiments corresponding to specific types of MCTs where machine intelligence has room to improve performance were performed using predictive coding, a more biologically plausible learning algorithm than backpropagation. This study regarded incremental learning, long-tailed, and few-shot recognition as representative MCTs. With extensive experiments, we examined the effectiveness of predictive coding that robustly outperformed backpropagation-trained networks for the MCTs. We demonstrated that predictive coding-based incremental learning alleviates the effect of catastrophic forgetting. Next, predictive coding-based learning mitigates the classification bias in long-tailed recognition. Finally, we verified that the network trained with predictive coding could correctly predict corresponding targets with few samples. From the experimental results, we observed that the brain-inspired predictive coding networks robustly outperformed backpropagation-trained networks for the MCTs tested. We analyzed the experimental result by drawing analogies between the properties of predictive coding networks and those of the human brain and discussing the potential of predictive coding networks in general machine learning.},
	language = {English},
	urldate = {2024-04-05},
	journal = {Frontiers in Computational Neuroscience},
	author = {Lee, Jangho and Jo, Jeonghee and Lee, Byounghwa and Lee, Jung-Hoon and Yoon, Sungroh},
	month = nov,
	year = {2022},
	note = {Publisher: Frontiers},
	keywords = {Brain-inspired Learning, Deep Learninig, backpropgation, biologically plausible learning, predictive coding},
}

@article{carandini_normalization_2011,
	title = {Normalization as a canonical neural computation},
	volume = {13},
	issn = {1471-003X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3273486/},
	doi = {10.1038/nrn3136},
	abstract = {There is increasing evidence that the brain relies on a set of canonical neural computations, repeating them across brain regions and modalities to apply similar operations to different problems. A promising candidate for such a computation is normalization, in which the responses of neurons are divided by a common factor that typically includes the summed activity of a pool of neurons. Normalization was developed to explain responses in the primary visual cortex and is now thought to operate throughout the visual system, and in many other sensory modalities and brain regions. Normalization may underlie operations such as the representation of odours, the modulatory effects of visual attention, the encoding of value and the integration of multisensory information. Its presence in such a diversity of neural systems in multiple species, from invertebrates to mammals, suggests that it serves as a canonical neural computation.},
	number = {1},
	urldate = {2024-04-05},
	journal = {Nature reviews. Neuroscience},
	author = {Carandini, Matteo and Heeger, David J.},
	month = nov,
	year = {2011},
	pmid = {22108672},
	pmcid = {PMC3273486},
	pages = {51--62},
}

@article{weber_coding_2019,
	title = {Coding {Principles} in {Adaptation}},
	volume = {5},
	issn = {2374-4650},
	doi = {10.1146/annurev-vision-091718-014818},
	abstract = {Adaptation is a common principle that recurs throughout the nervous system at all stages of processing. This principle manifests in a variety of phenomena, from spike frequency adaptation, to apparent changes in receptive fields with changes in stimulus statistics, to enhanced responses to unexpected stimuli. The ubiquity of adaptation leads naturally to the question: What purpose do these different types of adaptation serve? A diverse set of theories, often highly overlapping, has been proposed to explain the functional role of adaptive phenomena. In this review, we discuss several of these theoretical frameworks, highlighting relationships among them and clarifying distinctions. We summarize observations of the varied manifestations of adaptation, particularly as they relate to these theoretical frameworks, focusing throughout on the visual system and making connections to other sensory systems.},
	language = {eng},
	journal = {Annual Review of Vision Science},
	author = {Weber, Alison I. and Krishnamurthy, Kamesh and Fairhall, Adrienne L.},
	month = sep,
	year = {2019},
	pmid = {31283447},
	keywords = {Acclimatization, Adaptation, Physiological, Humans, Models, Neurological, Visual Perception, efficient coding, inference, neural coding, predictive coding, redundancy reduction, surprise},
	pages = {427--449},
}

@article{shen_correspondence_2021,
	title = {A {Correspondence} {Between} {Normalization} {Strategies} in {Artificial} and {Biological} {Neural} {Networks}},
	volume = {33},
	issn = {0899-7667},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8662716/},
	doi = {10.1162/neco_a_01439},
	abstract = {A fundamental challenge at the interface of machine learning and neuroscience is to uncover computational principles that are shared between artificial and biological neural networks. In deep learning, normalization methods such as batch normalization, weight normalization, and their many variants help to stabilize hidden unit activity and accelerate network training, and these methods have been called one of the most important recent innovations for optimizing deep networks. In the brain, homeostatic plasticity represents a set of mechanisms that also stabilize and normalize network activity to lie within certain ranges, and these mechanisms are critical for maintaining normal brain function. In this article, we discuss parallels between artificial and biological normalization methods at four spatial scales: normalization of a single neuron's activity, normalization of synaptic weights of a neuron, normalization of a layer of neurons, and normalization of a network of neurons. We argue that both types of methods are functionally equivalent—that is, both push activation patterns of hidden units toward a homeostatic state, where all neurons are equally used—and we argue that such representations can improve coding capacity, discrimination, and regularization. As a proof of concept, we develop an algorithm, inspired by a neural normalization technique called synaptic scaling, and show that this algorithm performs competitively against existing normalization methods on several data sets. Overall, we hope this bidirectional connection will inspire neuroscientists and machine learners in three ways: to uncover new normalization algorithms based on established neurobiological principles; to help quantify the trade-offs of different homeostatic plasticity mechanisms used in the brain; and to offer insights about how stability may not hinder, but may actually promote, plasticity.},
	number = {12},
	urldate = {2024-04-05},
	journal = {Neural Computation},
	author = {Shen, Yang and Wang, Julia and Navlakha, Saket},
	month = nov,
	year = {2021},
	pmid = {34474484},
	pmcid = {PMC8662716},
	pages = {3179--3203},
}

@misc{no_author_iris_2024,
	title = {\textit{{Iris}} flower data set},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Iris_flower_data_set&oldid=1210712220},
	abstract = {The Iris flower data set or Fisher's Iris data set is a multivariate data set used and made famous by the British statistician and biologist Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis. It is sometimes called Anderson's Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species. Two of the three species were collected in the Gaspé Peninsula "all from the same pasture, and picked on the same day and measured at the same time by the same person with the same apparatus".The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. Based on the combination of these four features, Fisher developed a linear discriminant model to distinguish the species from each other. Fisher's paper was published in the Annals of Eugenics (today the Annals of Human Genetics).},
	language = {en},
	urldate = {2024-02-28},
	journal = {Wikipedia},
	author = {No Author},
	month = feb,
	year = {2024},
	note = {Page Version ID: 1210712220},
}

@article{buhl_diverse_1994,
	title = {Diverse sources of hippocampal unitary inhibitory postsynaptic potentials and the number of synaptic release sites},
	volume = {368},
	issn = {0028-0836},
	doi = {10.1038/368823a0},
	abstract = {Dual intracellular recordings from microscopically identified neurons in the hippocampus reveal that the synaptic terminals of three morphologically distinct types of interneuron act through GABAA receptors. Each type of interneuron forms up to 12 synaptic contacts with a postsynaptic principal neuron, but each interneuron innervates a different domain of the surface of the postsynaptic neuron. Different kinetics of the postsynaptic effects, together with the strategic placement of synapses, indicate that these GABAergic interneurons serve distinct functions in the cortical network.},
	language = {eng},
	number = {6474},
	journal = {Nature},
	author = {Buhl, E. H. and Halasy, K. and Somogyi, P.},
	month = apr,
	year = {1994},
	pmid = {8159242},
	keywords = {Animals, Female, GABA-A Receptor Antagonists, Hippocampus, In Vitro Techniques, Interneurons, Neural Inhibition, Neural Pathways, Neurons, Rats, Rats, Wistar, Receptors, GABA-A, Synapses, Synaptic Transmission},
	pages = {823--828},
}

@article{waters_spiking_2011,
	title = {Spiking {Patterns} of {Neocortical} {L5} {Pyramidal} {Neurons} in {Vitro} {Change} with {Temperature}},
	volume = {5},
	issn = {1662-5102},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3031023/},
	doi = {10.3389/fncel.2011.00001},
	abstract = {A subset of pyramidal neurons in layer 5 of the mammalian neocortex can fire action potentials in brief, high-frequency bursts while others fire spikes at regularly spaced intervals. Here we show that individual layer 5 pyramidal neurons in acute slices from mouse primary motor cortex can adopt both regular and burst spiking patterns. During constant current injection at the soma, neurons displayed a regular firing pattern at 36–37°C, but switched to burst spiking patterns upon cooling the slice to 24–26°C. This change in firing pattern was reversible and repeatable and was independent of the somatic resting membrane potential. Hence these spiking patterns are not inherent to discrete populations of pyramidal neurons and are more interchangeable than previously thought. Burst spiking in these neurons is the result of electrical interactions between the soma and distal apical dendritic tree. Presumably the interactions between soma and distal dendrite are temperature-sensitive, suggesting that the manner in which layer 5 pyramidal neurons translate synaptic input into an output spiking pattern is fundamentally altered at sub-physiological temperatures.},
	urldate = {2024-04-05},
	journal = {Frontiers in Cellular Neuroscience},
	author = {Waters, Tristan Hedrickand Jack},
	month = jan,
	year = {2011},
	pmid = {21286222},
	pmcid = {PMC3031023},
	pages = {1},
}

@inproceedings{glorot_understanding_2010,
	title = {Understanding the difficulty of training deep feedforward neural networks},
	url = {https://proceedings.mlr.press/v9/glorot10a.html},
	abstract = {Whereas before 2006 it appears that deep multi-layer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future.  We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1.  Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence.},
	language = {en},
	urldate = {2024-04-05},
	booktitle = {Proceedings of the {Thirteenth} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {JMLR Workshop and Conference Proceedings},
	author = {Glorot, Xavier and Bengio, Yoshua},
	month = mar,
	year = {2010},
	note = {ISSN: 1938-7228},
	pages = {249--256},
}

@article{shouval_spike_2010,
	title = {Spike {Timing} {Dependent} {Plasticity}: {A} {Consequence} of {More} {Fundamental} {Learning} {Rules}},
	volume = {4},
	issn = {1662-5188},
	shorttitle = {Spike {Timing} {Dependent} {Plasticity}},
	url = {https://www.frontiersin.org/articles/10.3389/fncom.2010.00019},
	doi = {10.3389/fncom.2010.00019},
	abstract = {Spike timing dependent plasticity (STDP) is a phenomenon in which the precise timing of spikes affects the sign and magnitude of changes in synaptic strength. STDP is often interpreted as the comprehensive learning rule for a synapse - the \&ldquo;first law\&rdquo; of synaptic plasticity. This interpretation is made explicit in theoretical models in which the total plasticity produced by complex spike patterns results from a superposition of the effects of all spike pairs. Although such models are appealing for their simplicity, they can fail dramatically. For example, the measured single-spike learning rule between hippocampal CA3 and CA1 pyramidal neurons does not predict the existence of long-term potentiation. Layers of complexity have been added to the basic STDP model to repair predictive failures, but they have been outstripped by experimental data. We propose an alternate first law: neural activity triggers changes in key biochemical intermediates, which act as a more direct trigger of plasticity mechanisms. One particularly successful model uses intracellular calcium as the intermediate and can account for many observed properties of bidirectional plasticity. In this formulation, STDP is not itself the basis for explaining other forms of plasticity, but is instead a consequence of changes in the biochemical intermediate, calcium. Eventually a mechanism-based framework for learning rules should include other messengers, discrete change at individual synapses, spread of plasticity among neighboring synapses, and priming of hidden processes that change a synapse\&rsquo;s susceptibility to future change. Mechanism-based models provide a rich framework for the computational representation of synaptic plasticity.},
	language = {English},
	urldate = {2024-04-05},
	journal = {Frontiers in Computational Neuroscience},
	author = {Shouval, Harel Z. and Wang, Samuel S.-H. and Wittenberg, Gayle M.},
	month = jul,
	year = {2010},
	note = {Publisher: Frontiers},
	keywords = {Calcium, Long-Term Potentiation, Long-term depression, STDP, learning rules, mechanistic models, synaptic plasticity},
}

@article{abbott_lapicques_1999,
	title = {Lapicque's introduction of the integrate-and-fire model neuron (1907)},
	volume = {50},
	issn = {0361-9230},
	doi = {10.1016/s0361-9230(99)00161-6},
	language = {eng},
	number = {5-6},
	journal = {Brain Research Bulletin},
	author = {Abbott, L. F.},
	year = {1999},
	pmid = {10643408},
	keywords = {Electrophysiology, History, 20th Century, Models, Neurological, Neurons, Neurosciences},
	pages = {303--304},
}

@article{boerlin_predictive_2013,
	title = {Predictive {Coding} of {Dynamical} {Variables} in {Balanced} {Spiking} {Networks}},
	volume = {9},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003258},
	doi = {10.1371/journal.pcbi.1003258},
	abstract = {Two observations about the cortex have puzzled neuroscientists for a long time. First, neural responses are highly variable. Second, the level of excitation and inhibition received by each neuron is tightly balanced at all times. Here, we demonstrate that both properties are necessary consequences of neural networks that represent information efficiently in their spikes. We illustrate this insight with spiking networks that represent dynamical variables. Our approach is based on two assumptions: We assume that information about dynamical variables can be read out linearly from neural spike trains, and we assume that neurons only fire a spike if that improves the representation of the dynamical variables. Based on these assumptions, we derive a network of leaky integrate-and-fire neurons that is able to implement arbitrary linear dynamical systems. We show that the membrane voltage of the neurons is equivalent to a prediction error about a common population-level signal. Among other things, our approach allows us to construct an integrator network of spiking neurons that is robust against many perturbations. Most importantly, neural variability in our networks cannot be equated to noise. Despite exhibiting the same single unit properties as widely used population code models (e.g. tuning curves, Poisson distributed spike trains), balanced networks are orders of magnitudes more reliable. Our approach suggests that spikes do matter when considering how the brain computes, and that the reliability of cortical representations could have been strongly underestimated.},
	language = {en},
	number = {11},
	urldate = {2024-04-05},
	journal = {PLOS Computational Biology},
	author = {Boerlin, Martin and Machens, Christian K. and Denève, Sophie},
	month = nov,
	year = {2013},
	note = {Publisher: Public Library of Science},
	keywords = {Action potentials, Dynamical systems, Membrane potential, Network analysis, Neural networks, Neuronal tuning, Neurons, Sensory perception},
	pages = {e1003258},
}

@misc{meulemans_theoretical_2020,
	title = {A {Theoretical} {Framework} for {Target} {Propagation}},
	url = {http://arxiv.org/abs/2006.14331},
	doi = {10.48550/arXiv.2006.14331},
	abstract = {The success of deep learning, a brain-inspired form of AI, has sparked interest in understanding how the brain could similarly learn across multiple layers of neurons. However, the majority of biologically-plausible learning algorithms have not yet reached the performance of backpropagation (BP), nor are they built on strong theoretical foundations. Here, we analyze target propagation (TP), a popular but not yet fully understood alternative to BP, from the standpoint of mathematical optimization. Our theory shows that TP is closely related to Gauss-Newton optimization and thus substantially differs from BP. Furthermore, our analysis reveals a fundamental limitation of difference target propagation (DTP), a well-known variant of TP, in the realistic scenario of non-invertible neural networks. We provide a first solution to this problem through a novel reconstruction loss that improves feedback weight training, while simultaneously introducing architectural flexibility by allowing for direct feedback connections from the output to each hidden layer. Our theory is corroborated by experimental results that show significant improvements in performance and in the alignment of forward weight updates with loss gradients, compared to DTP.},
	urldate = {2024-04-05},
	publisher = {arXiv},
	author = {Meulemans, Alexander and Carzaniga, Francesco S. and Suykens, Johan A. K. and Sacramento, João and Grewe, Benjamin F.},
	month = dec,
	year = {2020},
	note = {arXiv:2006.14331 [cs, stat]},
	keywords = {68T07, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{bengio_how_2014,
	title = {How {Auto}-{Encoders} {Could} {Provide} {Credit} {Assignment} in {Deep} {Networks} via {Target} {Propagation}},
	url = {http://arxiv.org/abs/1407.7906},
	doi = {10.48550/arXiv.1407.7906},
	abstract = {We propose to exploit \{{\textbackslash}em reconstruction\} as a layer-local training signal for deep learning. Reconstructions can be propagated in a form of target propagation playing a role similar to back-propagation but helping to reduce the reliance on derivatives in order to perform credit assignment across many levels of possibly strong non-linearities (which is difficult for back-propagation). A regularized auto-encoder tends produce a reconstruction that is a more likely version of its input, i.e., a small move in the direction of higher likelihood. By generalizing gradients, target propagation may also allow to train deep networks with discrete hidden units. If the auto-encoder takes both a representation of input and target (or of any side information) in input, then its reconstruction of input representation provides a target towards a representation that is more likely, conditioned on all the side information. A deep auto-encoder decoding path generalizes gradient propagation in a learned way that can could thus handle not just infinitesimal changes but larger, discrete changes, hopefully allowing credit assignment through a long chain of non-linear operations. In addition to each layer being a good auto-encoder, the encoder also learns to please the upper layers by transforming the data into a space where it is easier to model by them, flattening manifolds and disentangling factors. The motivations and theoretical justifications for this approach are laid down in this paper, along with conjectures that will have to be verified either mathematically or experimentally, including a hypothesis stating that such auto-encoder mediated target propagation could play in brains the role of credit assignment through many non-linear, noisy and discrete transformations.},
	urldate = {2024-04-05},
	publisher = {arXiv},
	author = {Bengio, Yoshua},
	month = sep,
	year = {2014},
	note = {arXiv:1407.7906 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{bastos_canonical_2012,
	title = {Canonical microcircuits for predictive coding},
	volume = {76},
	issn = {0896-6273},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3777738/},
	doi = {10.1016/j.neuron.2012.10.038},
	abstract = {This review considers the influential notion of a canonical (cortical) microcircuit in light of recent theories about neuronal processing. Specifically, we conciliate quantitative studies of microcircuitry and the functional logic of neuronal computations. We revisit the established idea that message passing among hierarchical cortical areas implements a form of Bayesian inference – paying careful attention to the implications for intrinsic connections among neuronal populations. By deriving canonical forms for these computations, one can associate specific neuronal populations with specific computational roles. This analysis discloses a remarkable correspondence between the microcircuitry of the cortical column and the connectivity implied by predictive coding. Furthermore, it provides some intuitive insights into the functional asymmetries between feedforward and feedback connections and the characteristic frequencies over which they operate.},
	number = {4},
	urldate = {2024-04-05},
	journal = {Neuron},
	author = {Bastos, Andre M. and Usrey, W. Martin and Adams, Rick A. and Mangun, George R. and Fries, Pascal and Friston, Karl J.},
	month = nov,
	year = {2012},
	pmid = {23177956},
	pmcid = {PMC3777738},
	pages = {695--711},
}

@article{mikulasch_where_2023,
	title = {Where is the error? {Hierarchical} predictive coding through dendritic error computation},
	volume = {46},
	issn = {0166-2236, 1878-108X},
	shorttitle = {Where is the error?},
	url = {https://www.cell.com/trends/neurosciences/abstract/S0166-2236(22)00186-2},
	doi = {10.1016/j.tins.2022.09.007},
	abstract = {{\textless}h2{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Top-down feedback in cortex is critical for guiding sensory processing, which has prominently been formalized in the theory of hierarchical predictive coding (hPC). However, experimental evidence for error units, which are central to the theory, is inconclusive and it remains unclear how hPC can be implemented with spiking neurons. To address this, we connect hPC to existing work on efficient coding in balanced networks with lateral inhibition and predictive computation at apical dendrites. Together, this work points to an efficient implementation of hPC with spiking neurons, where prediction errors are computed not in separate units, but locally in dendritic compartments. We then discuss the correspondence of this model to experimentally observed connectivity patterns, plasticity, and dynamics in cortex.{\textless}/p{\textgreater}},
	language = {English},
	number = {1},
	urldate = {2024-04-05},
	journal = {Trends in Neurosciences},
	author = {Mikulasch, Fabian A. and Rudelt, Lucas and Wibral, Michael and Priesemann, Viola},
	month = jan,
	year = {2023},
	pmid = {36577388},
	note = {Publisher: Elsevier},
	pages = {45--59},
}

@article{song_can_nodate,
	title = {Can the {Brain} {Do} {Backpropagation}? — {Exact} {Implementation} of {Backpropagation} in {Predictive} {Coding} {Networks}},
	abstract = {Backpropagation (BP) has been the most successful algorithm used to train artiﬁcial neural networks. However, there are several gaps between BP and learning in biologically plausible neuronal networks of the brain (learning in the brain, or simply BL, for short), in particular, (1) it has been unclear to date, if BP can be implemented exactly via BL, (2) there is a lack of local plasticity in BP, i.e., weight updates require information that is not locally available, while BL utilizes only locally available information, and (3) there is a lack of autonomy in BP, i.e., some external control over the neural network is required (e.g., switching between prediction and learning stages requires changes to dynamics and synaptic plasticity rules), while BL works fully autonomously. Bridging such gaps, i.e., understanding how BP can be approximated by BL, has been of major interest in both neuroscience and machine learning. Despite tremendous efforts, however, no previous model has bridged the gaps at a degree of demonstrating an equivalence to BP, instead, only approximations to BP have been shown. Here, we present for the ﬁrst time a framework within BL that bridges the above crucial gaps. We propose a BL model that (1) produces exactly the same updates of the neural weights as BP, while (2) employing local plasticity, i.e., all neurons perform only local computations, done simultaneously. We then modify it to an alternative BL model that (3) also works fully autonomously. Overall, our work provides important evidence for the debate on the long-disputed question whether the brain can perform BP.},
	language = {en},
	author = {Song, Yuhang and Lukasiewicz, Thomas and Xu, Zhenghua and Bogacz, Rafal},
}

@misc{noauthor_predictive_nodate,
	title = {Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects {\textbar} {Nature} {Neuroscience}},
	url = {https://www.nature.com/articles/nn0199_79},
	urldate = {2024-04-05},
}

@inproceedings{hinton_learning_1987,
	title = {Learning {Representations} by {Recirculation}},
	volume = {0},
	url = {https://proceedings.neurips.cc/paper/1987/hash/35f4a8d465e6e1edc05f3d8ab658c551-Abstract.html},
	abstract = {We describe a new learning procedure for networks that contain groups of non(cid:173)},
	urldate = {2024-04-05},
	booktitle = {Neural {Information} {Processing} {Systems}},
	publisher = {American Institute of Physics},
	author = {Hinton, Geoffrey E and McClelland, James},
	year = {1987},
}

@misc{noauthor_frontiers_nodate,
	title = {Frontiers {\textbar} {Equilibrium} {Propagation}: {Bridging} the {Gap} between {Energy}-{Based} {Models} and {Backpropagation}},
	url = {https://www.frontiersin.org/articles/10.3389/fncom.2017.00024/full},
	urldate = {2024-04-05},
}

@inproceedings{sacramento_dendritic_2018,
	title = {Dendritic cortical microcircuits approximate the backpropagation algorithm},
	volume = {31},
	url = {https://papers.nips.cc/paper_files/paper/2018/hash/1dc3a89d0d440ba31729b0ba74b93a33-Abstract.html},
	abstract = {Deep learning has seen remarkable developments over the last years, many of them inspired by neuroscience. However, the main learning mechanism behind these advances – error backpropagation – appears to be at odds with neurobiology. Here, we introduce a multilayer neuronal network model with simplified dendritic compartments in which error-driven synaptic plasticity adapts the network towards a global desired output. In contrast to previous work our model does not require separate phases and synaptic learning is driven by local dendritic prediction errors continuously in time. Such errors originate at apical dendrites and occur due to a mismatch between predictive input from lateral interneurons and activity from actual top-down feedback. Through the use of simple dendritic compartments and different cell-types our model can represent both error and normal activity within a pyramidal neuron. We demonstrate the learning capabilities of the model in regression and classification tasks, and show analytically that it approximates the error backpropagation algorithm. Moreover, our framework is consistent with recent observations of learning between brain areas and the architecture of cortical microcircuits. Overall, we introduce a novel view of learning on dendritic cortical circuits and on how the brain may solve the long-standing synaptic credit assignment problem.},
	urldate = {2024-04-05},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Sacramento, João and Ponte Costa, Rui and Bengio, Yoshua and Senn, Walter},
	year = {2018},
}

@article{oreilly_biologically_1996,
	title = {Biologically {Plausible} {Error}-{Driven} {Learning} {Using} {Local} {Activation} {Differences}: {The} {Generalized} {Recirculation} {Algorithm}},
	volume = {8},
	issn = {0899-7667},
	shorttitle = {Biologically {Plausible} {Error}-{Driven} {Learning} {Using} {Local} {Activation} {Differences}},
	url = {https://ieeexplore.ieee.org/document/6796552},
	doi = {10.1162/neco.1996.8.5.895},
	abstract = {The error backpropagation learning algorithm (BP) is generally considered biologically implausible because it does not use locally available, activation-based variables. A version of BP that can be computed locally using bidirectional activation recirculation (Hinton and McClelland 1988) instead of backpropagated error derivatives is more biologically plausible. This paper presents a generalized version of the recirculation algorithm (GeneRec), which overcomes several limitations of the earlier algorithm by using a generic recurrent network with sigmoidal units that can learn arbitrary input/output mappings. However, the contrastive Hebbian learning algorithm (CHL, also known as DBM or mean field learning) also uses local variables to perform error-driven learning in a sigmoidal recurrent network. CHL was derived in a stochastic framework (the Boltzmann machine), but has been extended to the deterministic case in various ways, all of which rely on problematic approximations and assumptions, leading some to conclude that it is fundamentally flawed. This paper shows that CHL can be derived instead from within the BP framework via the GeneRec algorithm. CHL is a symmetry-preserving version of GeneRec that uses a simple approximation to the midpoint or second-order accurate Runge-Kutta method of numerical integration, which explains the generally faster learning speed of CHL compared to BI. Thus, all known fully general error-driven learning algorithms that use local activation-based variables in deterministic networks can be considered variations of the GeneRec algorithm (and indirectly, of the backpropagation algorithm). GeneRec therefore provides a promising framework for thinking about how the brain might perform error-driven learning. To further this goal, an explicit biological mechanism is proposed that would be capable of implementing GeneRec-style learning. This mechanism is consistent with available evidence regarding synaptic modification in neurons in the neocortex and hippocampus, and makes further predictions.},
	number = {5},
	urldate = {2024-04-05},
	journal = {Neural Computation},
	author = {O'Reilly, Randall C.},
	month = jul,
	year = {1996},
	note = {Conference Name: Neural Computation},
	pages = {895--938},
}

@article{song_inferring_2024,
	title = {Inferring neural activity before plasticity as a foundation for learning beyond backpropagation},
	volume = {27},
	copyright = {2024 The Author(s)},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-023-01514-1},
	doi = {10.1038/s41593-023-01514-1},
	abstract = {For both humans and machines, the essence of learning is to pinpoint which components in its information processing pipeline are responsible for an error in its output, a challenge that is known as ‘credit assignment’. It has long been assumed that credit assignment is best solved by backpropagation, which is also the foundation of modern machine learning. Here, we set out a fundamentally different principle on credit assignment called ‘prospective configuration’. In prospective configuration, the network first infers the pattern of neural activity that should result from learning, and then the synaptic weights are modified to consolidate the change in neural activity. We demonstrate that this distinct mechanism, in contrast to backpropagation, (1) underlies learning in a well-established family of models of cortical circuits, (2) enables learning that is more efficient and effective in many contexts faced by biological organisms and (3) reproduces surprising patterns of neural activity and behavior observed in diverse human and rat learning experiments.},
	language = {en},
	number = {2},
	urldate = {2024-04-05},
	journal = {Nature Neuroscience},
	author = {Song, Yuhang and Millidge, Beren and Salvatori, Tommaso and Lukasiewicz, Thomas and Xu, Zhenghua and Bogacz, Rafal},
	month = feb,
	year = {2024},
	note = {Publisher: Nature Publishing Group},
	keywords = {Learning algorithms, Machine learning, Network models},
	pages = {348--358},
}

@article{lillicrap_backpropagation_2020,
	title = {Backpropagation and the brain},
	volume = {21},
	copyright = {2020 Springer Nature Limited},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/s41583-020-0277-3},
	doi = {10.1038/s41583-020-0277-3},
	abstract = {During learning, the brain modifies synapses to improve behaviour. In the cortex, synapses are embedded within multilayered networks, making it difficult to determine the effect of an individual synaptic modification on the behaviour of the system. The backpropagation algorithm solves this problem in deep artificial neural networks, but historically it has been viewed as biologically problematic. Nonetheless, recent developments in neuroscience and the successes of artificial neural networks have reinvigorated interest in whether backpropagation offers insights for understanding learning in the cortex. The backpropagation algorithm learns quickly by computing synaptic updates using feedback connections to deliver error signals. Although feedback connections are ubiquitous in the cortex, it is difficult to see how they could deliver the error signals required by strict formulations of backpropagation. Here we build on past and recent developments to argue that feedback connections may instead induce neural activities whose differences can be used to locally approximate these signals and hence drive effective learning in deep networks in the brain.},
	language = {en},
	number = {6},
	urldate = {2024-04-05},
	journal = {Nature Reviews Neuroscience},
	author = {Lillicrap, Timothy P. and Santoro, Adam and Marris, Luke and Akerman, Colin J. and Hinton, Geoffrey},
	month = jun,
	year = {2020},
	note = {Publisher: Nature Publishing Group},
	keywords = {Cortex, Learning algorithms, Long-term potentiation, Network models, Neurophysiology},
	pages = {335--346},
}

@article{fisher_use_1936,
	title = {The {Use} of {Multiple} {Measurements} in {Taxonomic} {Problems}},
	volume = {7},
	copyright = {1936 Blackwell Publishing Ltd/University College London},
	issn = {2050-1439},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-1809.1936.tb02137.x},
	doi = {10.1111/j.1469-1809.1936.tb02137.x},
	abstract = {The articles published by the Annals of Eugenics (1925–1954) have been made available online as an historical archive intended for scholarly use. The work of eugenicists was often pervaded by prejudice against racial, ethnic and disabled groups. The online publication of this material for scholarly research purposes is not an endorsement of those views nor a promotion of eugenics in any way.},
	language = {en},
	number = {2},
	urldate = {2024-04-04},
	journal = {Annals of Eugenics},
	author = {Fisher, R. A.},
	year = {1936},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1469-1809.1936.tb02137.x},
	pages = {179--188},
}

@article{deng_mnist_2012,
	title = {The {MNIST} {Database} of {Handwritten} {Digit} {Images} for {Machine} {Learning} {Research} [{Best} of the {Web}]},
	volume = {29},
	issn = {1558-0792},
	url = {https://ieeexplore.ieee.org/document/6296535},
	doi = {10.1109/MSP.2012.2211477},
	abstract = {In this issue, “Best of the Web” presents the modified National Institute of Standards and Technology (MNIST) resources, consisting of a collection of handwritten digit images used extensively in optical character recognition and machine learning research.},
	number = {6},
	urldate = {2024-04-03},
	journal = {IEEE Signal Processing Magazine},
	author = {Deng, Li},
	month = nov,
	year = {2012},
	note = {Conference Name: IEEE Signal Processing Magazine},
	keywords = {Machine learning},
	pages = {141--142},
}

@misc{noauthor_biologically_nodate,
	title = {Biologically {Plausible} {Error}-{Driven} {Learning} {Using} {Local} {Activation} {Differences}: {The} {Generalized} {Recirculation} {Algorithm} {\textbar} {MIT} {Press} {Journals} \& {Magazine} {\textbar} {IEEE} {Xplore}},
	url = {https://ieeexplore.ieee.org/document/6796552},
	urldate = {2024-04-01},
}

@misc{noauthor_learning_nodate,
	title = {Learning {Representations} by {Recirculation}},
	url = {https://proceedings.neurips.cc/paper/1987/hash/35f4a8d465e6e1edc05f3d8ab658c551-Abstract.html},
	urldate = {2024-04-01},
}

@article{mnih_playing_nodate,
	title = {Playing {Atari} with {Deep} {Reinforcement} {Learning}},
	abstract = {We present the ﬁrst deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We ﬁnd that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
	language = {en},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
}

@misc{lee_difference_2015,
	title = {Difference {Target} {Propagation}},
	url = {http://arxiv.org/abs/1412.7525},
	doi = {10.48550/arXiv.1412.7525},
	abstract = {Back-propagation has been the workhorse of recent successes of deep learning but it relies on infinitesimal effects (partial derivatives) in order to perform credit assignment. This could become a serious issue as one considers deeper and more non-linear functions, e.g., consider the extreme case of nonlinearity where the relation between parameters and cost is actually discrete. Inspired by the biological implausibility of back-propagation, a few approaches have been proposed in the past that could play a similar credit assignment role. In this spirit, we explore a novel approach to credit assignment in deep networks that we call target propagation. The main idea is to compute targets rather than gradients, at each layer. Like gradients, they are propagated backwards. In a way that is related but different from previously proposed proxies for back-propagation which rely on a backwards network with symmetric weights, target propagation relies on auto-encoders at each layer. Unlike back-propagation, it can be applied even when units exchange stochastic bits rather than real numbers. We show that a linear correction for the imperfectness of the auto-encoders, called difference target propagation, is very effective to make target propagation actually work, leading to results comparable to back-propagation for deep networks with discrete and continuous units and denoising auto-encoders and achieving state of the art for stochastic networks.},
	urldate = {2024-03-26},
	publisher = {arXiv},
	author = {Lee, Dong-Hyun and Zhang, Saizheng and Fischer, Asja and Bengio, Yoshua},
	month = nov,
	year = {2015},
	note = {arXiv:1412.7525 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@article{davis_case_2021,
	title = {A case of frontal lobe syndrome},
	volume = {30},
	issn = {0972-6748},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8611603/},
	doi = {10.4103/0972-6748.328859},
	number = {Suppl 1},
	urldate = {2024-03-25},
	journal = {Industrial Psychiatry Journal},
	author = {Davis, Supriya and Gupta, Nishtha and Samudra, Madhura and Javadekar, Archana},
	month = oct,
	year = {2021},
	pmid = {34908739},
	pmcid = {PMC8611603},
	pages = {S360--S361},
}

@article{collins_reasoning_2012,
	title = {Reasoning, {Learning}, and {Creativity}: {Frontal} {Lobe} {Function} and {Human} {Decision}-{Making}},
	volume = {10},
	issn = {1544-9173},
	shorttitle = {Reasoning, {Learning}, and {Creativity}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3313946/},
	doi = {10.1371/journal.pbio.1001293},
	abstract = {Computational modeling and behavioral experimentation suggest that human frontal lobe function is capable of monitoring three or four concurrent behavioral strategies in order to select the most suitable one during decision-making., The frontal lobes subserve decision-making and executive control—that is, the selection and coordination of goal-directed behaviors. Current models of frontal executive function, however, do not explain human decision-making in everyday environments featuring uncertain, changing, and especially open-ended situations. Here, we propose a computational model of human executive function that clarifies this issue. Using behavioral experiments, we show that unlike others, the proposed model predicts human decisions and their variations across individuals in naturalistic situations. The model reveals that for driving action, the human frontal function monitors up to three/four concurrent behavioral strategies and infers online their ability to predict action outcomes: whenever one appears more reliable than unreliable, this strategy is chosen to guide the selection and learning of actions that maximize rewards. Otherwise, a new behavioral strategy is tentatively formed, partly from those stored in long-term memory, then probed, and if competitive confirmed to subsequently drive action. Thus, the human executive function has a monitoring capacity limited to three or four behavioral strategies. This limitation is compensated by the binary structure of executive control that in ambiguous and unknown situations promotes the exploration and creation of new behavioral strategies. The results support a model of human frontal function that integrates reasoning, learning, and creative abilities in the service of decision-making and adaptive behavior., Reasoning, learning, and creativity are hallmarks of human intelligence. These abilities involve the frontal lobe of the brain, but it remains unclear how the frontal lobes function in uncertain or open-ended situations. We propose here a computational model of human executive function that integrates multiple processes during decision-making, such as expectedness of uncertainty, task switching, and reinforcement learning. The model was tested in behavioral experiments and accounts for human decisions and their variations across individuals. The model reveals that executive function is capable of monitoring three or four concurrent behavioral strategies and infers online strategies' ability to predict action outcomes. If one strategy appears to reliably predict action outcomes, then it is chosen and possibly adjusted; otherwise a new strategy is tentatively formed, probed, and chosen instead. Thus, human frontal function has a monitoring capacity limited to three or four behavioral strategies. The results support a model of frontal executive function that explains the role and limitations of human reasoning, learning, and creative abilities in decision-making and adaptive behavior.},
	number = {3},
	urldate = {2024-03-25},
	journal = {PLoS Biology},
	author = {Collins, Anne and Koechlin, Etienne},
	month = mar,
	year = {2012},
	pmid = {22479152},
	pmcid = {PMC3313946},
	pages = {e1001293},
}

@book{hebb_organization_1949,
	address = {Oxford, England},
	series = {The organization of behavior; a neuropsychological theory},
	title = {The organization of behavior; a neuropsychological theory},
	abstract = {"This book presents a theory of behavior that is based as far as possible on the physiology of the nervous system, and makes a sedulous attempt to find some community of neurological and psychological conceptions." Using the concept of the reverbatory circuit and the assumption that "some growth process or metabolic change" in neurones takes place as a result of repeated transmission across synapses, perceptual integration is described in terms of "cell-assemblies." Of 11 chapters, 4 are devoted to perceptual problems, 2 to learning, 2 to motivation, and 1 each to emotional disturbances and intelligence. 14-page bibliography. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	publisher = {Wiley},
	author = {Hebb, D. O.},
	year = {1949},
	note = {Pages: xix, 335},
}

@article{moser_place_2015,
	title = {Place {Cells}, {Grid} {Cells}, and {Memory}},
	volume = {7},
	issn = {1943-0264},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4315928/},
	doi = {10.1101/cshperspect.a021808},
	abstract = {The hippocampal system is critical for storage and retrieval of declarative memories, including memories for locations and events that take place at those locations. Spatial memories place high demands on capacity. Memories must be distinct to be recalled without interference and encoding must be fast. Recent studies have indicated that hippocampal networks allow for fast storage of large quantities of uncorrelated spatial information. The aim of the this article is to review and discuss some of this work, taking as a starting point the discovery of multiple functionally specialized cell types of the hippocampal–entorhinal circuit, such as place, grid, and border cells. We will show that grid cells provide the hippocampus with a metric, as well as a putative mechanism for decorrelation of representations, that the formation of environment-specific place maps depends on mechanisms for long-term plasticity in the hippocampus, and that long-term spatiotemporal memory storage may depend on offline consolidation processes related to sharp-wave ripple activity in the hippocampus. The multitude of representations generated through interactions between a variety of functionally specialized cell types in the entorhinal–hippocampal circuit may be at the heart of the mechanism for declarative memory formation., Hippocampal networks allow for fast storage of large quantities of uncorrelated spatial information. Functionally specialized cell types (e.g., place cells and grid cells) may form the basis of this system.},
	number = {2},
	urldate = {2024-03-25},
	journal = {Cold Spring Harbor Perspectives in Biology},
	author = {Moser, May-Britt and Rowland, David C. and Moser, Edvard I.},
	month = feb,
	year = {2015},
	pmid = {25646382},
	pmcid = {PMC4315928},
	pages = {a021808},
}

@article{french_catastrophic_1999,
	title = {Catastrophic forgetting in connectionist networks},
	volume = {3},
	issn = {1364-6613},
	url = {https://www.sciencedirect.com/science/article/pii/S1364661399012942},
	doi = {10.1016/S1364-6613(99)01294-2},
	abstract = {All natural cognitive systems, and, in particular, our own, gradually forget previously learned information. Plausible models of human cognition should therefore exhibit similar patterns of gradual forgetting of old information as new information is acquired. Only rarely does new learning in natural cognitive systems completely disrupt or erase previously learned information; that is, natural cognitive systems do not, in general, forget ‘catastrophically’. Unfortunately, though, catastrophic forgetting does occur under certain circumstances in distributed connectionist networks. The very features that give these networks their remarkable abilities to generalize, to function in the presence of degraded input, and so on, are found to be the root cause of catastrophic forgetting. The challenge in this field is to discover how to keep the advantages of distributed connectionist networks while avoiding the problem of catastrophic forgetting. In this article the causes, consequences and numerous solutions to the problem of catastrophic forgetting in neural networks are examined. The review will consider how the brain might have overcome this problem and will also explore the consequences of this solution for distributed connectionist networks.},
	number = {4},
	urldate = {2024-03-23},
	journal = {Trends in Cognitive Sciences},
	author = {French, Robert M.},
	month = apr,
	year = {1999},
	keywords = {Catastrophic forgetting, Connectionism, Connectionist networks, Interference, Learning, Memory},
	pages = {128--135},
}

@article{greedy_single-phase_2022,
	title = {Single-phase deep learning in cortico-cortical networks},
	volume = {35},
	url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/99088dffd5eab0babebcda4bc58bbcea-Abstract-Conference.html},
	language = {en},
	urldate = {2024-03-23},
	journal = {Advances in Neural Information Processing Systems},
	author = {Greedy, Will and Zhu, Heng Wei and Pemberton, Joseph and Mellor, Jack and Ponte Costa, Rui},
	month = dec,
	year = {2022},
	pages = {24213--24225},
}

@article{hinton_training_2002,
	title = {Training {Products} of {Experts} by {Minimizing} {Contrastive} {Divergence}},
	volume = {14},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/089976602760128018},
	doi = {10.1162/089976602760128018},
	abstract = {It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual “expert” models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called “contrastive divergence” whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data.},
	number = {8},
	urldate = {2024-03-23},
	journal = {Neural Computation},
	author = {Hinton, Geoffrey E.},
	month = aug,
	year = {2002},
	pages = {1771--1800},
}

@article{liao_how_2016,
	title = {How {Important} {Is} {Weight} {Symmetry} in {Backpropagation}?},
	volume = {30},
	issn = {2374-3468, 2159-5399},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/10279},
	doi = {10.1609/aaai.v30i1.10279},
	abstract = {Gradient backpropagation (BP) requires symmetric feedforward and feedback connections—the same weights must be used for forward and backward passes. This “weight transport problem” (Grossberg 1987) is thought to be one of the main reasons to doubt BP’s biologically plausibility. Using 15 different classiﬁcation datasets, we systematically investigate to what extent BP really depends on weight symmetry. In a study that turned out to be surprisingly similar in spirit to Lillicrap et al.’s demonstration (Lillicrap et al. 2014) but orthogonal in its results, our experiments indicate that: (1) the magnitudes of feedback weights do not matter to performance (2) the signs of feedback weights do matter—the more concordant signs between feedforward and their corresponding feedback connections, the better (3) with feedback weights having random magnitudes and 100\% concordant signs, we were able to achieve the same or even better performance than SGD. (4) some normalizations/stabilizations are indispensable for such asymmetric BP to work, namely Batch Normalization (BN) (Ioffe and Szegedy 2015) and/or a “Batch Manhattan” (BM) update rule.},
	language = {en},
	number = {1},
	urldate = {2024-03-23},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Liao, Qianli and Leibo, Joel and Poggio, Tomaso},
	month = feb,
	year = {2016},
}

@article{grossberg_competitive_1987,
	title = {Competitive learning: {From} interactive activation to adaptive resonance},
	volume = {11},
	issn = {0364-0213},
	shorttitle = {Competitive learning},
	url = {https://www.sciencedirect.com/science/article/pii/S0364021387800253},
	doi = {10.1016/S0364-0213(87)80025-3},
	abstract = {Functional and mechanistic comparisons are made between several network models of cognitive processing: competitive learning, interactive activation, adaptive resonance, and back propagation. The starting point of this comparison is the article of Rumelhart and Zipser (1985) on feature discovery through competitive learning. All the models which Rumelhart and Zipser (1985) have described were shown in Grossberg (1976b) to exhibit a type of learning which is temporally unstable. Competitive learning mechanisms can be stabilized in response to an arbitrary input environment by being supplemented with mechanisms for learning top-down expectancies, or templates; for matching bottom-up input patterns with the top-down expectancies; and for releasing orienting reactions in a mismatch situation, thereby updating short-term memory and searching for another internal representation. Network architectures which embody all of these mechanisms were called adaptive resonance models by Grossberg (1976c). Self-stabilizing learning models are candidates for use in real-world applications where unpredictable changes can occur in complex input environments. Competitive learning postulates are inconsistent with the postulates of the interactive activation model of McClelland and Rumelhart (1981), and suggest different levels of processing and interaction rules for the analysis of word recognition. Adaptive resonance models use these alternative levels and interaction rules. The selforganizing learning of an adaptive resonance model is compared and contrasted with the teacher-directed learning of a back propagation model. A number of criteria for evaluating real-time network models of cognitive processing are described and applied.},
	number = {1},
	urldate = {2024-03-23},
	journal = {Cognitive Science},
	author = {Grossberg, Stephen},
	month = jan,
	year = {1987},
	pages = {23--63},
}

@article{schultz_neural_1997,
	title = {A neural substrate of prediction and reward},
	volume = {275},
	issn = {0036-8075},
	doi = {10.1126/science.275.5306.1593},
	abstract = {The capacity to predict future events permits a creature to detect, model, and manipulate the causal structure of its interactions with its environment. Behavioral experiments suggest that learning is driven by changes in the expectations about future salient events such as rewards and punishments. Physiological work has recently complemented these studies by identifying dopaminergic neurons in the primate whose fluctuating output apparently signals changes or errors in the predictions of future salient and rewarding events. Taken together, these findings can be understood through quantitative theories of adaptive optimizing control.},
	language = {eng},
	number = {5306},
	journal = {Science (New York, N.Y.)},
	author = {Schultz, W. and Dayan, P. and Montague, P. R.},
	month = mar,
	year = {1997},
	pmid = {9054347},
	keywords = {Algorithms, Animals, Computer Simulation, Conditioning, Psychological, Cues, Dopamine, Learning, Mesencephalon, Models, Neurological, Neurons, Rats, Reward},
	pages = {1593--1599},
}

@inproceedings{stachenfeld_design_2014,
	title = {Design {Principles} of the {Hippocampal} {Cognitive} {Map}},
	volume = {27},
	url = {https://papers.nips.cc/paper_files/paper/2014/hash/dfd7468ac613286cdbb40872c8ef3b06-Abstract.html},
	abstract = {Hippocampal place fields have been shown to reflect behaviorally relevant aspects of space. For instance, place fields tend to be skewed along commonly traveled directions, they cluster around rewarded locations, and they are constrained by the geometric structure of the environment. We hypothesize a set of design principles for the hippocampal cognitive map that explain how place fields represent space in a way that facilitates navigation and reinforcement learning. In particular, we suggest that place fields encode not just information about the current location, but also predictions about future locations under the current transition distribution. Under this model, a variety of place field phenomena arise naturally from the structure of rewards, barriers, and directional biases as reflected in the transition policy. Furthermore, we demonstrate that this representation of space can support efficient reinforcement learning. We also propose that grid cells compute the eigendecomposition of place fields in part because is useful for segmenting an enclosure along natural boundaries. When applied recursively, this segmentation can be used to discover a hierarchical decomposition of space. Thus, grid cells might be involved in computing subgoals for hierarchical reinforcement learning.},
	urldate = {2024-03-20},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Stachenfeld, Kimberly L and Botvinick, Matthew and Gershman, Samuel J},
	year = {2014},
}

@article{rumelhart_learning_1986,
	title = {Learning representations by back-propagating errors},
	volume = {323},
	copyright = {1986 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/323533a0},
	doi = {10.1038/323533a0},
	abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal ‘hidden’ units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
	language = {en},
	number = {6088},
	urldate = {2024-03-19},
	journal = {Nature},
	author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
	month = oct,
	year = {1986},
	note = {Publisher: Nature Publishing Group},
	keywords = {Humanities and Social Sciences, Science, multidisciplinary},
	pages = {533--536},
}

@misc{noauthor_kbsafari_compatibility_nodate,
	title = {kb:safari\_compatibility [{Zotero} {Documentation}]},
	url = {https://www.zotero.org/support/kb/safari_compatibility},
	urldate = {2024-03-19},
}

@article{constantinescu_organizing_2016,
	title = {Organizing {Conceptual} {Knowledge} in {Humans} with a {Grid}-like {Code}},
	volume = {352},
	issn = {0036-8075},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5248972/},
	doi = {10.1126/science.aaf0941},
	abstract = {It has been hypothesized that the brain organizes concepts into a mental map, allowing conceptual relationships to be navigated in a similar fashion to space. Grid cells use a hexagonally-symmetric code to organize spatial representations and are the likely source of a precise hexagonal symmetry in the functional magnetic resonance imaging signal. Humans navigating conceptual two-dimensional knowledge showed the same hexagonal signal in a strikingly similar set of brain regions to those activated during spatial navigation. This grid-like signal is consistent across sessions acquired within an hour and more than a week apart. Our findings suggest that global relational codes may be used to organize non-spatial conceptual representations and that these codes may have hexagonal grid-like pattern when conceptual knowledge is laid out in two continuous dimensions.},
	number = {6292},
	urldate = {2024-03-19},
	journal = {Science (New York, N.Y.)},
	author = {Constantinescu, Alexandra O. and O’Reilly, Jill X. and Behrens, Timothy E. J.},
	month = jun,
	year = {2016},
	pmid = {27313047},
	pmcid = {PMC5248972},
	pages = {1464--1468},
}

@article{okeefe_place_1976,
	title = {Place units in the hippocampus of the freely moving rat},
	volume = {51},
	issn = {0014-4886},
	doi = {10.1016/0014-4886(76)90055-8},
	language = {eng},
	number = {1},
	journal = {Experimental Neurology},
	author = {O'Keefe, J.},
	month = apr,
	year = {1976},
	pmid = {1261644},
	keywords = {Animals, Drinking Behavior, Feeding Behavior, Hippocampus, Humans, Motor Activity, Neurons, Orientation, Rats, Smell, Theta Rhythm, Visual Perception},
	pages = {78--109},
}

@article{daw_model-based_2011,
	title = {Model-based influences on humans’ choices and striatal prediction errors},
	volume = {69},
	issn = {0896-6273},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3077926/},
	doi = {10.1016/j.neuron.2011.02.027},
	abstract = {The mesostriatal dopamine system is prominently implicated in model-free
reinforcement learning, with fMRI BOLD signals in ventral striatum notably
covarying with model-free prediction errors. However, latent learning and
devaluation studies show that behavior also shows hallmarks of model-based
planning, and the interaction between model-based and model-free values,
prediction errors and preferences is underexplored. We designed a multistep
decision task in which model-based and model-free influences on human choice
behavior could be distinguished. By showing that choices reflected both
influences we could then test the purity of the ventral striatal BOLD signal as
a model-free report. Contrary to expectations, the signal reflected both
model-free and model-based predictions in proportions matching those that best
explained choice behavior. These results challenge the notion of a separate
model-free learner and suggest a more integrated computational architecture for
high-level human decision-making.},
	number = {6},
	urldate = {2024-03-19},
	journal = {Neuron},
	author = {Daw, Nathaniel D. and Gershman, Samuel J. and Seymour, Ben and Dayan, Peter and Dolan, Raymond J.},
	month = mar,
	year = {2011},
	pmid = {21435563},
	pmcid = {PMC3077926},
	pages = {1204--1215},
}

@article{langdon_uncovering_2019,
	title = {Uncovering the ‘state’: tracing the hidden state representations that structure learning and decision-making},
	volume = {167},
	issn = {0376-6357},
	shorttitle = {Uncovering the ‘state’},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7388561/},
	doi = {10.1016/j.beproc.2019.103891},
	abstract = {We review the abstract concept of a ‘state’ – an internal representation posited by reinforcement learning theories to be used by an agent, whether animal, human or artificial, to summarize the features of the external and internal environment that are relevant for future behavior on a particular task. Armed with this summary representation, an agent can make decisions and perform actions to interact effectively with the world. Here, we review recent findings from the neurobiological and behavioral literature to ask: ‘what is a state?’ with respect to the internal representations that organize learning and decision making across a range of tasks. We find that state representations include information beyond a straightforward summary of the immediate cues in the environment, providing timing or contextual information from the recent or more distant past, which allows these additional factors to influence decision making and other goal-directed behaviors in complex and perhaps unexpected ways.},
	urldate = {2024-03-19},
	journal = {Behavioural processes},
	author = {Langdon, Angela J. and Song, Mingyu and Niv, Yael},
	month = oct,
	year = {2019},
	pmid = {31381985},
	pmcid = {PMC7388561},
	pages = {103891},
}

@article{berridge_motivation_2004,
	title = {Motivation concepts in behavioral neuroscience},
	volume = {81},
	issn = {0031-9384},
	doi = {10.1016/j.physbeh.2004.02.004},
	abstract = {Concepts of motivation are vital to progress in behavioral neuroscience. Motivational concepts help us to understand what limbic brain systems are chiefly evolved to do, i.e., to mediate psychological processes that guide real behavior. This article evaluates some major motivation concepts that have historic importance or have influenced the interpretation of behavioral neuroscience research. These concepts include homeostasis, setpoints and settling points, intervening variables, hydraulic drives, drive reduction, appetitive and consummatory behavior, opponent processes, hedonic reactions, incentive motivation, drive centers, dedicated drive neurons (and drive neuropeptides and receptors), neural hierarchies, and new concepts from affective neuroscience such as allostasis, cognitive incentives, and reward 'liking' versus 'wanting'.},
	language = {eng},
	number = {2},
	journal = {Physiology \& Behavior},
	author = {Berridge, Kent C.},
	month = apr,
	year = {2004},
	pmid = {15159167},
	keywords = {Animals, Behavioral Medicine, Drive, Humans, Motivation, Neurosciences},
	pages = {179--209},
}

@book{howard_dynamic_1960,
	address = {Oxford, England},
	series = {Dynamic programming and {Markov} processes},
	title = {Dynamic programming and {Markov} processes},
	abstract = {An analytic structure, based on the Markov process as a model, is developed for the description and analysis of complex systems. Both discrete-and continuous-time Markov process models are developed with illustrations of applications to production and other competitive systems. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	publisher = {John Wiley},
	author = {Howard, Ronald A.},
	year = {1960},
	note = {Pages: viii, 136},
}

@article{redgrave_basal_1999,
	title = {The basal ganglia: a vertebrate solution to the selection problem?},
	volume = {89},
	issn = {0306-4522, 1873-7544},
	shorttitle = {The basal ganglia},
	url = {https://www.ibroneuroscience.org/article/S0306-4522(98)00319-4/abstract},
	doi = {10.1016/S0306-4522(98)00319-4},
	language = {English},
	number = {4},
	urldate = {2024-03-19},
	journal = {Neuroscience},
	author = {Redgrave, P. and Prescott, T. J. and Gurney, K.},
	month = apr,
	year = {1999},
	note = {Publisher: Elsevier},
	pages = {1009--1023},
}

@article{murray_hierarchy_2014,
	title = {A hierarchy of intrinsic timescales across primate cortex},
	volume = {17},
	copyright = {2014 Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.3862},
	doi = {10.1038/nn.3862},
	abstract = {Primate cortex can be organized with specialization and hierarchical principles, but presently there is little evidence for how it is organized temporally. Across six separate datasets, the authors find a hierarchical ordering of intrinsic fluctuation of spiking activity, with timescales that increase from sensory to prefrontal areas.},
	language = {en},
	number = {12},
	urldate = {2024-03-19},
	journal = {Nature Neuroscience},
	author = {Murray, John D. and Bernacchia, Alberto and Freedman, David J. and Romo, Ranulfo and Wallis, Jonathan D. and Cai, Xinying and Padoa-Schioppa, Camillo and Pasternak, Tatiana and Seo, Hyojung and Lee, Daeyeol and Wang, Xiao-Jing},
	month = dec,
	year = {2014},
	note = {Publisher: Nature Publishing Group},
	keywords = {Dynamical systems},
	pages = {1661--1663},
}

@article{kirkpatrick_overcoming_2016,
	title = {Overcoming catastrophic forgetting in neural networks},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1612.00796},
	doi = {10.48550/ARXIV.1612.00796},
	abstract = {The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Neural networks are not, in general, capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks which they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on the MNIST hand written digit dataset and by learning several Atari 2600 games sequentially.},
	urldate = {2024-03-19},
	author = {Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A. and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and Hassabis, Demis and Clopath, Claudia and Kumaran, Dharshan and Hadsell, Raia},
	year = {2016},
	note = {Publisher: [object Object]
Version Number: 2},
	keywords = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences, Machine Learning (cs.LG), Machine Learning (stat.ML)},
}

@article{redgrave_goal-directed_2010,
	title = {Goal-directed and habitual control in the basal ganglia: implications for {Parkinson}'s disease},
	volume = {11},
	copyright = {2010 Springer Nature Limited},
	issn = {1471-0048},
	shorttitle = {Goal-directed and habitual control in the basal ganglia},
	url = {https://www.nature.com/articles/nrn2915},
	doi = {10.1038/nrn2915},
	abstract = {The basal ganglia are one of the fundamental processing units of the mammalian brain. Progressive degeneration of one of their major components, the ascending dopamine projection to the striatum, is a central pathological feature of Parkinson's disease.Imaging and post-mortem investigations reveal that degeneration of the dopamine projection is uneven in most cases, with input to caudolateral sectors of the putamen most severely affected.In the animal learning literature an important distinction has been forged between goal-directed and habitual control of behaviour. When behaviour is goal-directed, action selection is determined by the relative utility of predicted outcomes, whereas habits are under stimulus control and largely independent of outcome value.A seminal series of investigations in rodents by Balleine and colleagues established that the dorsomedial associative territories of the striatum are crucial for goal-directed control, whereas laterally located sensorimotor territories are essential for habits. Formal behavioural tests (for example, outcome devaluation) were used to determine whether an observed behaviour (for example, pressing a lever) was under goal-directed or habitual control.Recent neuroimaging studies using the same formal tests suggest that a similar spatial segregation of goal-directed and habitual control is present within the human striatum. As the loss of dopamine in Parkinson's disease is predominantly from the caudolateral sensorimotor territories, we would expect patients to experience major deficits in their production of habits.Because the same behavioural output can be directed by processing in spatially segregated regions of the basal ganglia, it must be assumed that the efferent projections of goal-directed and habitual control circuits must at some point converge on the 'final common motor path'.Given that the loss of dopamine in the basal ganglia is associated with enhanced oscillatory and inhibitory outputs, we suggest that for goal-directed control to be expressed, the distorting inhibitory signals from the habit system must be overcome at the point where the goal-directed and habitual control circuits converge.We conclude by reviewing evidence suggesting that many of the behavioural difficulties experienced by patients with Parkinson's disease can be interpreted in terms of an impaired automatic control of normal habits, coupled with distorting inhibitory influences imposed on the expression of residual goal-directed behaviours.In the light of this analysis, future work will need to establish how far the reported cognitive deficits in Parkinson's disease are due to the primary disease state (additional loss of dopamine from goal-directed circuits) or are a result of goal-directed control being overwhelmed by the absence of automatic control routines that are normally provided by the stimulus–response habit systems.},
	language = {en},
	number = {11},
	urldate = {2024-03-19},
	journal = {Nature Reviews Neuroscience},
	author = {Redgrave, Peter and Rodriguez, Manuel and Smith, Yoland and Rodriguez-Oroz, Maria C. and Lehericy, Stephane and Bergman, Hagai and Agid, Yves and DeLong, Mahlon R. and Obeso, Jose A.},
	month = nov,
	year = {2010},
	note = {Publisher: Nature Publishing Group},
	keywords = {Basal ganglia, Parkinson's disease},
	pages = {760--772},
}

@misc{noauthor_predictive_nodate-1,
	title = {Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects {\textbar} {Nature} {Neuroscience}},
	url = {https://www.nature.com/articles/nn0199_79},
	urldate = {2024-03-19},
}

@article{rao_predictive_1999,
	title = {Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects},
	volume = {2},
	copyright = {1999 Nature America Inc.},
	issn = {1546-1726},
	shorttitle = {Predictive coding in the visual cortex},
	url = {https://www.nature.com/articles/nn0199_79},
	doi = {10.1038/4580},
	abstract = {We describe a model of visual processing in which feedback connections from a higher- to a lower-order visual cortical area carry predictions of lower-level neural activities, whereas the feedforward connections carry the residual errors between the predictions and the actual lower-level activities. When exposed to natural images, a hierarchical network of model neurons implementing such a model developed simple-cell-like receptive fields. A subset of neurons responsible for carrying the residual errors showed endstopping and other extra-classical receptive-field effects. These results suggest that rather than being exclusively feedforward phenomena, nonclassical surround effects in the visual cortex may also result from cortico-cortical feedback as a consequence of the visual system using an efficient hierarchical strategy for encoding natural images.},
	language = {en},
	number = {1},
	urldate = {2024-03-19},
	journal = {Nature Neuroscience},
	author = {Rao, Rajesh P. N. and Ballard, Dana H.},
	month = jan,
	year = {1999},
	note = {Publisher: Nature Publishing Group},
	keywords = {Animal Genetics and Genomics, Behavioral Sciences, Biological Techniques, Biomedicine, Neurobiology, Neurosciences, general},
	pages = {79--87},
}

@misc{noauthor_predictive_nodate-2,
	title = {Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects {\textbar} {Nature} {Neuroscience}},
	url = {https://www.nature.com/articles/nn0199_79},
	urldate = {2024-03-19},
}

@inproceedings{saxe_neural_2022,
	title = {The {Neural} {Race} {Reduction}: {Dynamics} of {Abstraction} in {Gated} {Networks}},
	shorttitle = {The {Neural} {Race} {Reduction}},
	url = {https://proceedings.mlr.press/v162/saxe22a.html},
	abstract = {Our theoretical understanding of deep learning has not kept pace with its empirical success. While network architecture is known to be critical, we do not yet understand its effect on learned representations and network behavior, or how this architecture should reflect task structure.In this work, we begin to address this gap by introducing the Gated Deep Linear Network framework that schematizes how pathways of information flow impact learning dynamics within an architecture. Crucially, because of the gating, these networks can compute nonlinear functions of their input. We derive an exact reduction and, for certain cases, exact solutions to the dynamics of learning. Our analysis demonstrates that the learning dynamics in structured networks can be conceptualized as a neural race with an implicit bias towards shared representations, which then govern the model’s ability to systematically generalize, multi-task, and transfer. We validate our key insights on naturalistic datasets and with relaxed assumptions. Taken together, our work gives rise to general hypotheses relating neural architecture to learning and provides a mathematical approach towards understanding the design of more complex architectures and the role of modularity and compositionality in solving real-world problems. The code and results are available at https://www.saxelab.org/gated-dln.},
	language = {en},
	urldate = {2024-03-19},
	booktitle = {Proceedings of the 39th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Saxe, Andrew and Sodhani, Shagun and Lewallen, Sam Jay},
	month = jun,
	year = {2022},
	note = {ISSN: 2640-3498},
	pages = {19287--19309},
}

@article{flesch_continual_2023,
	title = {Continual task learning in natural and artificial agents},
	volume = {46},
	issn = {0166-2236, 1878-108X},
	url = {https://www.cell.com/trends/neurosciences/abstract/S0166-2236(22)00260-0},
	doi = {10.1016/j.tins.2022.12.006},
	abstract = {{\textless}h2{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}How do humans and other animals learn new tasks? A wave of brain recording studies has investigated how neural representations change during task learning, with a focus on how tasks can be acquired and coded in ways that minimise mutual interference. We review recent work that has explored the geometry and dimensionality of neural task representations in neocortex, and computational models that have exploited these findings to understand how the brain may partition knowledge between tasks. We discuss how ideas from machine learning, including those that combine supervised and unsupervised learning, are helping neuroscientists understand how natural tasks are learned and coded in biological brains.{\textless}/p{\textgreater}},
	language = {English},
	number = {3},
	urldate = {2024-03-19},
	journal = {Trends in Neurosciences},
	author = {Flesch, Timo and Saxe, Andrew and Summerfield, Christopher},
	month = mar,
	year = {2023},
	pmid = {36682991},
	note = {Publisher: Elsevier},
	pages = {199--210},
}

@article{dayan_model-based_2014,
	title = {Model-based and model-free {Pavlovian} reward learning: {Revaluation}, revision, and revelation},
	volume = {14},
	issn = {1531-135X},
	shorttitle = {Model-based and model-free {Pavlovian} reward learning},
	url = {https://doi.org/10.3758/s13415-014-0277-8},
	doi = {10.3758/s13415-014-0277-8},
	abstract = {Evidence supports at least two methods for learning about reward and punishment and making predictions for guiding actions. One method, called model-free, progressively acquires cached estimates of the long-run values of circumstances and actions from retrospective experience. The other method, called model-based, uses representations of the environment, expectations, and prospective calculations to make cognitive predictions of future value. Extensive attention has been paid to both methods in computational analyses of instrumental learning. By contrast, although a full computational analysis has been lacking, Pavlovian learning and prediction has typically been presumed to be solely model-free. Here, we revise that presumption and review compelling evidence from Pavlovian revaluation experiments showing that Pavlovian predictions can involve their own form of model-based evaluation. In model-based Pavlovian evaluation, prevailing states of the body and brain influence value computations, and thereby produce powerful incentive motivations that can sometimes be quite new. We consider the consequences of this revised Pavlovian view for the computational landscape of prediction, response, and choice. We also revisit differences between Pavlovian and instrumental learning in the control of incentive motivation.},
	language = {en},
	number = {2},
	urldate = {2024-03-19},
	journal = {Cognitive, Affective, \& Behavioral Neuroscience},
	author = {Dayan, Peter and Berridge, Kent C.},
	month = jun,
	year = {2014},
	keywords = {Basal ganglia, Decision making, Dopamine, Pavlovian, classical conditioning, Reward, Motivation},
	pages = {473--492},
}

@article{feher_da_silva_humans_2020,
	title = {Humans primarily use model-based inference in the two-stage task},
	volume = {4},
	issn = {2397-3374},
	url = {https://doi.org/10.1038/s41562-020-0905-y},
	doi = {10.1038/s41562-020-0905-y},
	abstract = {Distinct model-free and model-based learning processes are thought to drive both typical and dysfunctional behaviours. Data from two-stage decision tasks have seemingly shown that human behaviour is driven by both processes operating in parallel. However, in this study, we show that more detailed task instructions lead participants to make primarily model-based choices that have little, if any, simple model-free influence. We also demonstrate that behaviour in the two-stage task may falsely appear to be driven by a combination of simple model-free and model-based learning if purely model-based agents form inaccurate models of the task because of misconceptions. Furthermore, we report evidence that many participants do misconceive the task in important ways. Overall, we argue that humans formulate a wide variety of learning models. Consequently, the simple dichotomy of model-free versus model-based learning is inadequate to explain behaviour in the two-stage task and connections between reward learning, habit formation and compulsivity.},
	language = {en},
	number = {10},
	urldate = {2024-03-19},
	journal = {Nature Human Behaviour},
	author = {Feher da Silva, Carolina and Hare, Todd A.},
	month = oct,
	year = {2020},
	pages = {1053--1066},
}

@article{samuel_j_gershman_successor_2018,
	title = {The {Successor} {Representation}: {Its} {Computational} {Logic} and {Neural} {Substrates}},
	volume = {38},
	url = {http://www.jneurosci.org/content/38/33/7193.abstract},
	doi = {10.1523/JNEUROSCI.0151-18.2018},
	abstract = {Reinforcement learning is the process by which an agent learns to predict long-term future reward. We now understand a great deal about the brain's reinforcement learning algorithms, but we know considerably less about the representations of states and actions over which these algorithms operate. A useful starting point is asking what kinds of representations we would want the brain to have, given the constraints on its computational architecture. Following this logic leads to the idea of the successor representation, which encodes states of the environment in terms of their predictive relationships with other states. Recent behavioral and neural studies have provided evidence for the successor representation, and computational studies have explored ways to extend the original idea. This paper reviews progress on these fronts, organizing them within a broader framework for understanding how the brain negotiates tradeoffs between efficiency and flexibility for reinforcement learning.},
	number = {33},
	journal = {The Journal of Neuroscience},
	author = {{Samuel J. Gershman}},
	month = aug,
	year = {2018},
	pages = {7193},
}

@misc{gershman_successor_nodate,
	title = {The {Successor} {Representation}: {Its} {Computational} {Logic} and {Neural} {Substrates} {\textbar} {Journal} of {Neuroscience}},
	url = {https://www.jneurosci.org/content/38/33/7193},
	urldate = {2024-03-19},
	author = {Gershman, Samuel J.},
}

@article{asaad_prefrontal_2017,
	title = {Prefrontal {Neurons} {Encode} a {Solution} to the {Credit}-{Assignment} {Problem}},
	volume = {37},
	issn = {0270-6474},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5518425/},
	doi = {10.1523/JNEUROSCI.3311-16.2017},
	abstract = {To adapt successfully to our environments, we must use the outcomes of our choices to guide future behavior. Critically, we must be able to correctly assign credit for any particular outcome to the causal features which preceded it. In some cases, the causal features may be immediately evident, whereas in others they may be separated in time or intermingled with irrelevant environmental stimuli, creating a potentially nontrivial credit-assignment problem. We examined the neuronal representation of information relevant for credit assignment in the dorsolateral prefrontal cortex (dlPFC) of two male rhesus macaques performing a task that elicited key aspects of this problem. We found that neurons conveyed the information necessary for credit assignment. Specifically, neuronal activity reflected both the relevant cues and outcomes at the time of feedback and did so in a manner that was stable over time, in contrast to prior reports of representational instability in the dlPFC. Furthermore, these representations were most stable early in learning, when credit assignment was most needed. When the same features were not needed for credit assignment, these neuronal representations were much weaker or absent. These results demonstrate that the activity of dlPFC neurons conforms to the basic requirements of a system that performs credit assignment, and that spiking activity can serve as a stable mechanism that links causes and effects., SIGNIFICANCE STATEMENT Credit assignment is the process by which we infer the causes of our successes and failures. We found that neuronal activity in the dorsolateral prefrontal cortex conveyed the necessary information for performing credit assignment. Importantly, while there are various potential mechanisms to retain a “trace” of the causal events over time, we observed that spiking activity was sufficiently stable to act as the link between causes and effects, in contrast to prior reports that suggested spiking representations were unstable over time. In addition, we observed that this stability varied as a function of learning, such that the neural code was more reliable over time during early learning, when it was most needed.},
	number = {29},
	urldate = {2024-03-19},
	journal = {The Journal of Neuroscience},
	author = {Asaad, Wael F. and Lauro, Peter M. and Perge, János A. and Eskandar, Emad N.},
	month = jul,
	year = {2017},
	pmid = {28634307},
	pmcid = {PMC5518425},
	pages = {6995--7007},
}

@misc{noauthor_approximation_nodate,
	title = {An {Approximation} of the {Error} {Backpropagation} {Algorithm} in a {Predictive} {Coding} {Network} with {Local} {Hebbian} {Synaptic} {Plasticity} - {PubMed}},
	url = {https://pubmed.ncbi.nlm.nih.gov/28333583/},
	urldate = {2024-03-19},
}

@misc{bogacz_theory_2017,
	title = {Theory of reinforcement learning and motivation in the basal ganglia},
	copyright = {© 2017, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/174524v1},
	doi = {10.1101/174524},
	abstract = {This paper proposes how the neural circuits in vertebrates select actions on the basis of past experience and the current motivational state. According to the presented theory, the basal ganglia evaluate the utility of considered actions by combining the positive consequences (e.g. nutrition) scaled by the motivational state (e.g. hunger) with the negative consequences (e.g. effort). The theory suggests how the basal ganglia compute utility by combining the positive and negative consequences encoded in the synaptic weights of striatal Go and No-Go neurons, and the motivational state carried by neuromodulators including dopamine. Furthermore, the theory suggests how the striatal neurons to learn separately about consequences of actions, and how the dopaminergic neurons themselves learn what level of activity they need to produce to optimize behaviour. The theory accounts for the effects of dopaminergic modulation on behaviour, patterns of synaptic plasticity in striatum, and responses of dopaminergic neurons in diverse situations.},
	language = {en},
	urldate = {2024-03-19},
	publisher = {bioRxiv},
	author = {Bogacz, Rafal},
	month = aug,
	year = {2017},
	note = {Pages: 174524
Section: New Results},
}

@book{sutton_reinforcement_2018,
	title = {Reinforcement {Learning}, second edition: {An} {Introduction}},
	isbn = {978-0-262-35270-3},
	shorttitle = {Reinforcement {Learning}, second edition},
	abstract = {The significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence.Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms. This second edition has been significantly expanded and updated, presenting new topics and updating coverage of other topics.Like the first edition, this second edition focuses on core online learning algorithms, with the more mathematical material set off in shaded boxes. Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found. Many algorithms presented in this part are new to the second edition, including UCB, Expected Sarsa, and Double Learning. Part II extends these ideas to function approximation, with new sections on such topics as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods. Part III has new chapters on reinforcement learning's relationships to psychology and neuroscience, as well as an updated case-studies chapter including AlphaGo and AlphaGo Zero, Atari game playing, and IBM Watson's wagering strategy. The final chapter discusses the future societal impacts of reinforcement learning.},
	language = {en},
	publisher = {MIT Press},
	author = {Sutton, Richard S. and Barto, Andrew G.},
	month = nov,
	year = {2018},
	note = {Google-Books-ID: uWV0DwAAQBAJ},
	keywords = {Computers / Artificial Intelligence / General},
}

@misc{el-gaby_cellular_2023,
	title = {A {Cellular} {Basis} for {Mapping} {Behavioural} {Structure}},
	copyright = {© 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2023.11.04.565609v1},
	doi = {10.1101/2023.11.04.565609},
	abstract = {To flexibly adapt to new situations, our brains must understand the regularities in the world, but also in our own patterns of behaviour. A wealth of findings is beginning to reveal the algorithms we use to map the outside world1–6. In contrast, the biological algorithms that map the complex structured behaviours we compose to reach our goals remain enigmatic. Here we reveal a neuronal implementation of an algorithm for mapping abstract behavioural structure and transferring it to new scenarios. We trained mice on many tasks which shared a common structure organising a sequence of goals, but differed in the specific goal locations. Animals discovered the underlying task structure, enabling zero-shot inferences on the first trial of new tasks. The activity of most neurons in the medial Frontal cortex tiled progress-to-goal, akin to how place cells map physical space. These “goal-progress cells” generalised, stretching and compressing their tiling to accommodate different goal distances. In contrast, progress along the overall sequence of goals was not encoded explicitly. Instead a subset of goal-progress cells was further tuned such that individual neurons fired with a fixed task-lag from a particular behavioural step. Together these cells implemented an algorithm that instantaneously encoded the entire sequence of future behavioural steps, and whose dynamics automatically retrieved the appropriate action at each step. These dynamics mirrored the abstract task structure both on-task and during offline sleep. Our findings suggest that goal-progress cells in the medial frontal cortex may be elemental building blocks of schemata that can be sculpted to represent complex behavioural structures.},
	language = {en},
	urldate = {2024-03-19},
	publisher = {bioRxiv},
	author = {El-Gaby, Mohamady and Harris, Adam Loyd and Whittington, James C. R. and Dorrell, William and Bhomick, Arya and Walton, Mark E. and Akam, Thomas and Behrens, Tim E. J.},
	month = nov,
	year = {2023},
	note = {Pages: 2023.11.04.565609
Section: New Results},
}

@article{urbanczik_learning_2014,
	title = {Learning by the {Dendritic} {Prediction} of {Somatic} {Spiking}},
	volume = {81},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627313011276},
	doi = {10.1016/j.neuron.2013.11.030},
	abstract = {Recent modeling of spike-timing-dependent plasticity indicates that plasticity involves as a third factor a local dendritic potential, besides pre- and postsynaptic firing times. We present a simple compartmental neuron model together with a non-Hebbian, biologically plausible learning rule for dendritic synapses where plasticity is modulated by these three factors. In functional terms, the rule seeks to minimize discrepancies between somatic firings and a local dendritic potential. Such prediction errors can arise in our model from stochastic fluctuations as well as from synaptic input, which directly targets the soma. Depending on the nature of this direct input, our plasticity rule subserves supervised or unsupervised learning. When a reward signal modulates the learning rate, reinforcement learning results. Hence a single plasticity rule supports diverse learning paradigms.},
	number = {3},
	urldate = {2024-03-14},
	journal = {Neuron},
	author = {Urbanczik, Robert and Senn, Walter},
	month = feb,
	year = {2014},
	pages = {521--528},
}

@article{hodgkin_quantitative_1952,
	title = {A quantitative description of membrane current and its application to conduction and excitation in nerve},
	volume = {117},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1392413/},
	doi = {10.1113/jphysiol.1952.sp004764},
	language = {en},
	number = {4},
	urldate = {2024-03-14},
	journal = {The Journal of Physiology},
	author = {Hodgkin, A. L. and Huxley, A. F.},
	month = aug,
	year = {1952},
	pmid = {12991237},
	note = {Publisher: Wiley-Blackwell},
	pages = {500},
}

@misc{carter_tensorflow_nodate,
	title = {Tensorflow — {Neural} {Network} {Playground}},
	url = {http://playground.tensorflow.org},
	abstract = {Tinker with a real neural network right here in your browser.},
	urldate = {2024-03-05},
	author = {Carter, Daniel Smilkov {and} Shan},
}

@misc{ellis_dreamcoder_2020,
	title = {{DreamCoder}: {Growing} generalizable, interpretable knowledge with wake-sleep {Bayesian} program learning},
	shorttitle = {{DreamCoder}},
	url = {http://arxiv.org/abs/2006.08381},
	doi = {10.48550/arXiv.2006.08381},
	abstract = {Expert problem-solving is driven by powerful languages for thinking about problems and their solutions. Acquiring expertise means learning these languages -- systems of concepts, alongside the skills to use them. We present DreamCoder, a system that learns to solve problems by writing programs. It builds expertise by creating programming languages for expressing domain concepts, together with neural networks to guide the search for programs within these languages. A ``wake-sleep'' learning algorithm alternately extends the language with new symbolic abstractions and trains the neural network on imagined and replayed problems. DreamCoder solves both classic inductive programming tasks and creative tasks such as drawing pictures and building scenes. It rediscovers the basics of modern functional programming, vector algebra and classical physics, including Newton's and Coulomb's laws. Concepts are built compositionally from those learned earlier, yielding multi-layered symbolic representations that are interpretable and transferrable to new tasks, while still growing scalably and flexibly with experience.},
	urldate = {2024-03-04},
	publisher = {arXiv},
	author = {Ellis, Kevin and Wong, Catherine and Nye, Maxwell and Sable-Meyer, Mathias and Cary, Luc and Morales, Lucas and Hewitt, Luke and Solar-Lezama, Armando and Tenenbaum, Joshua B.},
	month = jun,
	year = {2020},
	note = {arXiv:2006.08381 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{hopfield_computing_1986,
	title = {Computing with {Neural} {Circuits}: {A} {Model}},
	volume = {233},
	shorttitle = {Computing with {Neural} {Circuits}},
	url = {https://www.science.org/doi/abs/10.1126/science.3755256},
	doi = {10.1126/science.3755256},
	abstract = {A new conceptual framework and a minimization principle together provide an understanding of computation in model neural circuits. The circuits consist of nonlinear graded-response model neurons organized into networks with effectively symmetric synaptic connections. The neurons represent an approximation to biological neurons in which a simplified set of important computational properties is retained. Complex circuits solving problems similar to those essential in biology can be analyzed and understood without the need to follow the circuit dynamics in detail. Implementation of the model with electronic devices will provide a class of electronic circuits of novel form and function.},
	number = {4764},
	urldate = {2024-03-04},
	journal = {Science},
	author = {Hopfield, John J. and Tank, David W.},
	month = aug,
	year = {1986},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {625--633},
}

@article{song_inferring_2024-1,
	title = {Inferring neural activity before plasticity as a foundation for learning beyond backpropagation},
	volume = {27},
	copyright = {2024 The Author(s)},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-023-01514-1},
	doi = {10.1038/s41593-023-01514-1},
	abstract = {For both humans and machines, the essence of learning is to pinpoint which components in its information processing pipeline are responsible for an error in its output, a challenge that is known as ‘credit assignment’. It has long been assumed that credit assignment is best solved by backpropagation, which is also the foundation of modern machine learning. Here, we set out a fundamentally different principle on credit assignment called ‘prospective configuration’. In prospective configuration, the network first infers the pattern of neural activity that should result from learning, and then the synaptic weights are modified to consolidate the change in neural activity. We demonstrate that this distinct mechanism, in contrast to backpropagation, (1) underlies learning in a well-established family of models of cortical circuits, (2) enables learning that is more efficient and effective in many contexts faced by biological organisms and (3) reproduces surprising patterns of neural activity and behavior observed in diverse human and rat learning experiments.},
	language = {en},
	number = {2},
	urldate = {2024-03-02},
	journal = {Nature Neuroscience},
	author = {Song, Yuhang and Millidge, Beren and Salvatori, Tommaso and Lukasiewicz, Thomas and Xu, Zhenghua and Bogacz, Rafal},
	month = feb,
	year = {2024},
	note = {Number: 2
Publisher: Nature Publishing Group},
	keywords = {Learning algorithms, Machine learning, Network models},
	pages = {348--358},
}

@article{quiroga_invariant_2005,
	title = {Invariant visual representation by single neurons in the human brain},
	volume = {435},
	issn = {1476-4687},
	doi = {10.1038/nature03687},
	abstract = {It takes a fraction of a second to recognize a person or an object even when seen under strikingly different conditions. How such a robust, high-level representation is achieved by neurons in the human brain is still unclear. In monkeys, neurons in the upper stages of the ventral visual pathway respond to complex images such as faces and objects and show some degree of invariance to metric properties such as the stimulus size, position and viewing angle. We have previously shown that neurons in the human medial temporal lobe (MTL) fire selectively to images of faces, animals, objects or scenes. Here we report on a remarkable subset of MTL neurons that are selectively activated by strikingly different pictures of given individuals, landmarks or objects and in some cases even by letter strings with their names. These results suggest an invariant, sparse and explicit code, which might be important in the transformation of complex visual percepts into long-term and more abstract memories.},
	language = {eng},
	number = {7045},
	journal = {Nature},
	author = {Quiroga, R. Quian and Reddy, L. and Kreiman, G. and Koch, C. and Fried, I.},
	month = jun,
	year = {2005},
	pmid = {15973409},
	keywords = {Adolescent, Adult, Brain, Face, Female, Hippocampus, Humans, Male, Memory, Middle Aged, Models, Neurological, Neurons, Pattern Recognition, Visual, ROC Curve, Substrate Specificity, Temporal Lobe},
	pages = {1102--1107},
}

@article{beyeler_neural_2019,
	title = {Neural correlates of sparse coding and dimensionality reduction},
	volume = {15},
	issn = {1553-734X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6597036/},
	doi = {10.1371/journal.pcbi.1006908},
	abstract = {Supported by recent computational studies, there is increasing evidence that a wide range of neuronal responses can be understood as an emergent property of nonnegative sparse coding (NSC), an efficient population coding scheme based on dimensionality reduction and sparsity constraints. We review evidence that NSC might be employed by sensory areas to efficiently encode external stimulus spaces, by some associative areas to conjunctively represent multiple behaviorally relevant variables, and possibly by the basal ganglia to coordinate movement. In addition, NSC might provide a useful theoretical framework under which to understand the often complex and nonintuitive response properties of neurons in other brain areas. Although NSC might not apply to all brain areas (for example, motor or executive function areas) the success of NSC-based models, especially in sensory areas, warrants further investigation for neural correlates in other regions., Brains face the fundamental challenge of extracting relevant information from high-dimensional external stimuli in order to form the neural basis that can guide an organism's behavior and its interaction with the world. One potential approach to addressing this challenge is to reduce the number of variables required to represent a particular input space (i.e., dimensionality reduction). We review compelling evidence that a range of neuronal responses can be understood as an emergent property of nonnegative sparse coding (NSC)—a form of efficient population coding due to dimensionality reduction and sparsity constraints.},
	number = {6},
	urldate = {2024-02-22},
	journal = {PLoS Computational Biology},
	author = {Beyeler, Michael and Rounds, Emily L. and Carlson, Kristofor D. and Dutt, Nikil and Krichmar, Jeffrey L.},
	month = jun,
	year = {2019},
	pmid = {31246948},
	pmcid = {PMC6597036},
	pages = {e1006908},
}

@incollection{clark_artificial_1998,
	address = {Dordrecht},
	title = {Artificial {Keys} for {Botanical} {Identification} using a {Multilayer} {Perceptron} {Neural} {Network} ({MLP})},
	isbn = {978-94-011-5048-4},
	url = {https://doi.org/10.1007/978-94-011-5048-4_5},
	abstract = {In this paper, practical generation of identification keys for biological taxa using a multilayer perceptron neural network is described. Unlike conventional expert systems, this method does not require an expert for key generation, but is merely based on recordings of observed character states. Like a human taxonomist, its judgement is based on experience, and it is therefore capable of generalized identification of taxa. An initial study involving identification of three species of Iris with greater than 90\% confidence is presented here. In addition, the horticulturally significant genus Lithops (Aizoaceae/Mesembryanthemaceae), popular with enthusiasts of succulent plants, is used as a more practical example, because of the difficulty of generation of a conventional key to species, and the existence of a relatively recent monograph. It is demonstrated that such an Artificial Neural Network Key (ANNKEY) can identify more than half (52.9\%) of the species in this genus, after training with representative data, even though data for one character is completely missing.},
	language = {en},
	urldate = {2024-02-05},
	booktitle = {Artificial {Intelligence} for {Biology} and {Agriculture}},
	publisher = {Springer Netherlands},
	author = {Clark, Jonathan Y. and Warwick, Kevin},
	editor = {Panigrahi, S. and Ting, K. C.},
	year = {1998},
	doi = {10.1007/978-94-011-5048-4_5},
	keywords = {Aizoaceae, Iris, Lithops, Mesembryan-themaceae, expert system, identification, key, multilayer perceptrons, neural network},
	pages = {95--115},
}

@incollection{panigrahi_artificial_1998,
	address = {Dordrecht},
	title = {Artificial {Keys} for {Botanical} {Identification} using a {Multilayer} {Perceptron} {Neural} {Network} ({MLP})},
	isbn = {978-94-010-6120-9 978-94-011-5048-4},
	url = {http://link.springer.com/10.1007/978-94-011-5048-4_5},
	abstract = {In this paper, practical generation of identiﬁcation keys for biological taxa using a multilayer perceptron neural network is described. Unlike conventional expert systems, this method does not require an expert for key generation, but is merely based on recordings of observed character states. Like a human taxonomist, its judgement is based on experience, and it is therefore capable of generalized identiﬁcation of taxa. An initial study involving identiﬁcation of three species of Iris with greater than 90\% conﬁdence is presented here. In addition, the horticulturally signiﬁcant genus Lithops (Aizoaceae/Mesembryanthemaceae), popular with enthusiasts of succulent plants, is used as a more practical example, because of the difﬁculty of generation of a conventional key to species, and the existence of a relatively recent monograph. It is demonstrated that such an Artiﬁcial Neural Network Key (ANNKEY) can identify more than half (52.9\%) of the species in this genus, after training with representative data, even though data for one character is completely missing.},
	language = {en},
	urldate = {2024-02-05},
	booktitle = {Artificial {Intelligence} for {Biology} and {Agriculture}},
	publisher = {Springer Netherlands},
	author = {Clark, Jonathan Y. and Warwick, Kevin},
	editor = {Panigrahi, S. and Ting, K. C.},
	year = {1998},
	doi = {10.1007/978-94-011-5048-4_5},
	pages = {95--115},
}

@article{richards_dendritic_2019,
	series = {Neurobiology of {Learning} and {Plasticity}},
	title = {Dendritic solutions to the credit assignment problem},
	volume = {54},
	issn = {0959-4388},
	url = {https://www.sciencedirect.com/science/article/pii/S0959438818300485},
	doi = {10.1016/j.conb.2018.08.003},
	abstract = {Guaranteeing that synaptic plasticity leads to effective learning requires a means for assigning credit to each neuron for its contribution to behavior. The ‘credit assignment problem’ refers to the fact that credit assignment is non-trivial in hierarchical networks with multiple stages of processing. One difficulty is that if credit signals are integrated with other inputs, then it is hard for synaptic plasticity rules to distinguish credit-related activity from non-credit-related activity. A potential solution is to use the spatial layout and non-linear properties of dendrites to distinguish credit signals from other inputs. In cortical pyramidal neurons, evidence hints that top-down feedback signals are integrated in the distal apical dendrites and have a distinct impact on spike-firing and synaptic plasticity. This suggests that the distal apical dendrites of pyramidal neurons help the brain to solve the credit assignment problem.},
	urldate = {2024-02-05},
	journal = {Current Opinion in Neurobiology},
	author = {Richards, Blake A and Lillicrap, Timothy P},
	month = feb,
	year = {2019},
	keywords = {neuroscience},
	pages = {28--36},
}

@misc{noauthor_san_nodate,
	title = {san soleil - {YouTube}},
	url = {https://www.youtube.com/},
	abstract = {Enjoy the videos and music you love, upload original content, and share it all with friends, family, and the world on YouTube.},
	language = {en},
	urldate = {2023-12-30},
}

@misc{eddyoshi_reflections_2023,
	type = {Reddit {Post}},
	title = {Reflections from a former {James} {Somerton} fan.},
	url = {www.reddit.com/r/hbomberguy/comments/18ebr1f/reflections_from_a_former_james_somerton_fan/},
	urldate = {2023-12-09},
	journal = {r/hbomberguy},
	author = {Eddyoshi},
	month = dec,
	year = {2023},
}

@article{whittington_approximation_2017,
	title = {An {Approximation} of the {Error} {Backpropagation} {Algorithm} in a {Predictive} {Coding} {Network} with {Local} {Hebbian} {Synaptic} {Plasticity}},
	volume = {29},
	issn = {0899-7667, 1530-888X},
	url = {https://direct.mit.edu/neco/article/29/5/1229/8261/An-Approximation-of-the-Error-Backpropagation},
	doi = {10.1162/NECO_a_00949},
	abstract = {Abstract
            To efficiently learn from feedback, cortical networks need to update synaptic weights on multiple levels of cortical hierarchy. An effective and well-known algorithm for computing such changes in synaptic weights is the error backpropagation algorithm. However, in this algorithm, the change in synaptic weights is a complex function of weights and activities of neurons not directly connected with the synapse being modified, whereas the changes in biological synapses are determined only by the activity of presynaptic and postsynaptic neurons. Several models have been proposed that approximate the backpropagation algorithm with local synaptic plasticity, but these models require complex external control over the network or relatively complex plasticity rules. Here we show that a network developed in the predictive coding framework can efficiently perform supervised learning fully autonomously, employing only simple local Hebbian plasticity. Furthermore, for certain parameters, the weight change in the predictive coding model converges to that of the backpropagation algorithm. This suggests that it is possible for cortical networks with simple Hebbian synaptic plasticity to implement efficient learning algorithms in which synapses in areas on multiple levels of hierarchy are modified to minimize the error on the output.},
	language = {en},
	number = {5},
	urldate = {2023-12-08},
	journal = {Neural Computation},
	author = {Whittington, James C. R. and Bogacz, Rafal},
	month = may,
	year = {2017},
	keywords = {PCN\_paper},
	pages = {1229--1262},
}

@article{whittington_how_2022,
	title = {How to build a cognitive map},
	volume = {25},
	issn = {1546-1726},
	url = {https://doi.org/10.1038/s41593-022-01153-y},
	doi = {10.1038/s41593-022-01153-y},
	abstract = {Learning and interpreting the structure of the environment is an innate feature of biological systems, and is integral to guiding flexible behaviors for evolutionary viability. The concept of a cognitive map has emerged as one of the leading metaphors for these capacities, and unraveling the learning and neural representation of such a map has become a central focus of neuroscience. In recent years, many models have been developed to explain cellular responses in the hippocampus and other brain areas. Because it can be difficult to see how these models differ, how they relate and what each model can contribute, this Review aims to organize these models into a clear ontology. This ontology reveals parallels between existing empirical results, and implies new approaches to understand hippocampal–cortical interactions and beyond.},
	number = {10},
	journal = {Nature Neuroscience},
	author = {Whittington, James C. R. and McCaffary, David and Bakermans, Jacob J. W. and Behrens, Timothy E. J.},
	month = oct,
	year = {2022},
	pages = {1257--1272},
}
